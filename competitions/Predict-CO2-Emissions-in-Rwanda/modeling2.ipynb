{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1idXIFLjmkggTCk1K34BNt3n5ojRWl-oB",
      "authorship_tag": "ABX9TyPXrGegI3roCTLEgFjWi8vP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbdus0715/Machine-Learning/blob/main/competitions/Predict-CO2-Emissions-in-Rwanda/modeling2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XIQ4Ztt36hk4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "seed = 2023\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/MyDrive/'\n",
        "train = pd.read_csv(path + 'train.csv')\n",
        "test = pd.read_csv(path + 'test.csv')"
      ],
      "metadata": {
        "id": "JqsyQi2e6zpU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (1) 피처 엔지니어링 - 군집화"
      ],
      "metadata": {
        "id": "I-kiQP1uquG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def kmeans_clustering(df, cluster_num, max_iter=1000):\n",
        "    scaler = StandardScaler()\n",
        "    df_std = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)\n",
        "\n",
        "    km_model = KMeans(n_clusters=cluster_num, max_iter=max_iter, random_state=666)\n",
        "    km_model.fit(df_std)\n",
        "\n",
        "    cluster_df = pd.DataFrame(data=km_model.labels_, columns=['ClusterNo'], index=df.index)\n",
        "\n",
        "    return cluster_df"
      ],
      "metadata": {
        "id": "Z2ihvuE8qyNF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emission_series = train.pivot_table(\n",
        "    index=['year', 'week_no'],\n",
        "    columns=['longitude', 'latitude'],\n",
        "    values='emission'\n",
        ")\n",
        "\n",
        "emission_series = (emission_series - emission_series.min()) / (emission_series.max() - emission_series.min())\n",
        "emission_series = emission_series.dropna(axis=1)"
      ],
      "metadata": {
        "id": "ibEwXrORswkx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cluster = emission_series.copy()\n",
        "df_cluster = df_cluster.T\n",
        "cluster_num = 8\n",
        "\n",
        "df_cluster['ClusterNo'] = kmeans_clustering(df=df_cluster, cluster_num=cluster_num, max_iter=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6cmGWoTsv-G",
        "outputId": "90b2b195-c8ff-4b2a-ef6d-39a72e03e20e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.merge(df_cluster['ClusterNo'].reset_index(), on=['longitude', 'latitude'], how='left').fillna(-1)\n",
        "test = test.merge(df_cluster['ClusterNo'].reset_index(),on=['longitude','latitude'],how='left').fillna(-1)"
      ],
      "metadata": {
        "id": "pAL4tcDdMtxZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) 모델링"
      ],
      "metadata": {
        "id": "ScwyywBWqyfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 위도 경도를 하나의 id로 만드는 함수\n",
        "def get_id(row):\n",
        "    return int(''.join(filter(str.isdigit, str(row['latitude']))) + ''.join(filter(str.isdigit, str(row['longitude']))))\n",
        "\n",
        "# 람다함수로 적용하여 모든 위치에 대해 id로 대응\n",
        "train['id'] = train[['latitude', 'longitude']].apply(lambda row: get_id(row), axis=1)\n",
        "test['id'] = test[['latitude', 'longitude']].apply(lambda row: get_id(row), axis=1)\n",
        "\n",
        "# 새로운 유니크한 아이디로 매핑\n",
        "new_ids = {id_: new_id for new_id, id_ in enumerate((train['id']).unique())}\n",
        "train['id'] = train['id'].map(new_ids)\n",
        "test['id'] = test['id'].map(new_ids)"
      ],
      "metadata": {
        "id": "w-9uSjls7ARA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install haversine"
      ],
      "metadata": {
        "id": "Lt9N29HBf_yP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881544f4-b322-49f6-fc18-b7202e85d452"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: haversine in /usr/local/lib/python3.10/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rwanda_center = (-1.9607, 29.9707)\n",
        "park_biega = (-1.8866, 28.4518)\n",
        "kirumba = (-0.5658, 29.1714)\n",
        "massif = (-2.9677, 28.6469)\n",
        "lake = (-1.9277, 31.4346)\n",
        "mbarara = (-0.692, 30.602)\n",
        "muy = (-2.8374, 30.3346)"
      ],
      "metadata": {
        "id": "3fCav4WQ2s93"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haversine import haversine\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "\n",
        "def cluster_features(df, cluster_centers):\n",
        "    # 군집의 중앙 좌표 정보 순회\n",
        "    for i, cc in enumerate(cluster_centers.values()):\n",
        "        # 군집의 중앙과 해당 군집 원소들 사이의 거리를 구함\n",
        "        df[f'cluster_{i}'] = df.apply(lambda x: haversine((x['latitude'], x['longitude']), cc, unit='ft'), axis=1)\n",
        "    return df\n",
        "\n",
        "def get_month(row):\n",
        "    # lambda 함수로 사용됨\n",
        "    # dataframe의 한 row에 대해 year, week_no 정보를 이용하여 datetime 객체를 만듦\n",
        "    date = dt.datetime.strptime(f'{row[\"year\"]}-{row[\"week_no\"]+1}-1', \"%Y-%W-%w\")\n",
        "    return date.month\n",
        "\n",
        "def coor_rotation(df):\n",
        "    df['rot_15_x'] = (np.cos(np.radians(15)) * df['longitude']) + \\\n",
        "                     (np.sin(np.radians(15)) * df['latitude'])\n",
        "\n",
        "    df['rot_15_y'] = (np.cos(np.radians(15)) * df['latitude']) + \\\n",
        "                     (np.sin(np.radians(15)) * df['longitude'])\n",
        "\n",
        "    df['rot_30_x'] = (np.cos(np.radians(30)) * df['longitude']) + \\\n",
        "                     (np.sin(np.radians(30)) * df['latitude'])\n",
        "\n",
        "    df['rot_30_y'] = (np.cos(np.radians(30)) * df['latitude']) + \\\n",
        "                     (np.sin(np.radians(30)) * df['longitude'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "8Ck3am0KVomM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['emission']\n",
        "\n",
        "# 피처 엔지니어링\n",
        "def preprocessing(df):\n",
        "    cols_save = ['id', 'latitude', 'longitude', 'year', 'week_no', 'Ozone_solar_azimuth_angle', 'ClusterNo']\n",
        "    df = df[cols_save]\n",
        "\n",
        "    # 지역, 연도로 그룹화한 후, 특정 칼럼 칼럼의 결측지 채워넣기\n",
        "    good_col = 'Ozone_solar_azimuth_angle'\n",
        "    df[good_col] = df.groupby(['id', 'year'])[good_col].ffill().bfill()\n",
        "\n",
        "    # 위의 값을 아래로 한칸씩 이동시킨 후 널값 제거\n",
        "    df[f'{good_col}_lag_1'] = df.groupby(['id', 'year'])[good_col].shift(1).fillna(0)\n",
        "\n",
        "    # 15도, 30도 회전시킨 결과 구하기\n",
        "    df = coor_rotation(df)\n",
        "\n",
        "    for col, coors in zip(\n",
        "        ['dist_rwanda', 'dist_park', 'dist_kirumba', 'dist_massif', 'dist_lake', 'dist_mbarara', 'dist_muy'],\n",
        "        [rwanda_center, park_biega, kirumba, massif, lake, mbarara, muy]\n",
        "    ):\n",
        "        # 리스트 안을 순회하며 거리 계산\n",
        "        df[col] = df.apply(lambda x: haversine((x['latitude'], x['longitude']), coors, unit='ft'), axis=1)\n",
        "\n",
        "\n",
        "    # 월 계산\n",
        "    df['month'] = df[['year', 'week_no']].apply(lambda row: get_month(row), axis=1)\n",
        "    # 해당 년도가 코로나 유행 기간이었는지\n",
        "    df['is_covid'] = (df['year'] == 2020) & (df['month'] > 2) | (df['year'] == 2021) & (df['month'] == 1)\n",
        "    # 봉쇄령 기간이었는지\n",
        "    df['is_lockdown'] = (df['year'] == 2020) & ((df['month'].isin([3,4])))\n",
        "    # 코로나 최고점\n",
        "    df['is_covid_peak'] = (df['year'] == 2020) & ((df['month'].isin([4,5,6])))\n",
        "    # 코로나 감소세\n",
        "    df['is_covid_dis_peak'] = (df['year'] == 2021) & ((df['month'].isin([7,8,9])))\n",
        "    # 공휴일\n",
        "    df['public_holidays'] = (df['week_no'].isin([0, 51, 12, 30]))\n",
        "\n",
        "    df.fillna(0, inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "PhBFVRZ3fsY4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = preprocessing(train)\n",
        "test = preprocessing(test)\n",
        "\n",
        "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
        "\n",
        "# 위도 경도 군집화 (좌표에 따른)\n",
        "coordinates = df[['latitude', 'longitude']].values\n",
        "clustering = KMeans(n_clusters=12, max_iter=1000, random_state=seed).fit(coordinates)\n",
        "cluster_centers = {i: tuple(centroid) for i, centroid in enumerate(clustering.cluster_centers_)}\n",
        "df = cluster_features(df, cluster_centers)\n",
        "\n",
        "train = df.iloc[:-len(test), :]\n",
        "test = df.iloc[:len(test), :]\n",
        "del df\n",
        "\n",
        "X = train.drop('id', axis=1)\n",
        "test = test.drop('id', axis=1)"
      ],
      "metadata": {
        "id": "Nd6gxL76BT6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "final_preds = np.zeros(len(test))\n",
        "train['emission'] = y\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=1000, random_state=seed, n_jobs=-1, verbose=1)\n",
        "rf.fit(X, y)\n",
        "final_preds = rf.predict(test)\n",
        "\n",
        "final_preds"
      ],
      "metadata": {
        "id": "tJ93RUP2C9Ye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fd71d9-d48d-4a72-e3a2-c38d53553f5d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  3.74822333,   4.06070595,   4.23404496, ..., 124.06861931,\n",
              "       123.9804968 , 124.00352398])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ss = pd.read_csv(path + 'sample_submission.csv')"
      ],
      "metadata": {
        "id": "qgNwdgrRR73W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss['emission'] = final_preds"
      ],
      "metadata": {
        "id": "5t2kWOmMYVUQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3) 후처리"
      ],
      "metadata": {
        "id": "s-W0IrrpYj0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ss['id'] = np.array(train[(train['week_no']<49) & (train['year']==2021)]['id'])\n",
        "ss['week_no'] = ss.groupby('id').cumcount()"
      ],
      "metadata": {
        "id": "ice4EV06YjpG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs_pred_cluster = [1.10, #ClusterNo 0\n",
        "                       1.02, #ClusterNo 1\n",
        "                       1.10, #ClusterNo 2\n",
        "                       1.07, #ClusterNo 3\n",
        "                       1.10, #ClusterNo 4\n",
        "                       1.05, #ClusterNo 5\n",
        "                       1.07, #ClusterNo 6\n",
        "                       1.07, #7\n",
        "                      ]\n",
        "\n",
        "test = test.reset_index(drop=True)\n",
        "for ClusterNo in range(8):\n",
        "    ss.loc[test['ClusterNo']==ClusterNo, 'emission'] = ss.loc[test['ClusterNo']==ClusterNo, 'emission']*coeffs_pred_cluster[ClusterNo]"
      ],
      "metadata": {
        "id": "kZbgHgPLYf1n"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss.loc[test['longitude']==29.321, 'emission'] = train.loc[(train['year']==2021)&(train['week_no']<=48)&(train['longitude']==29.321),'emission'].values\n",
        "\n",
        "coeff_29222 = 1.10\n",
        "ss.loc[test['longitude']==29.222, 'emission'] = pd.Series(final_preds).loc[test['longitude']==29.222].values * coeff_29222"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "IXeRCgvQYhKf",
        "outputId": "eaef8278-7861-4793-ad01-a2d4778986d9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2bdfda6a1529>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m29.321\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emission'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week_no'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m&\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m29.321\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'emission'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcoeff_29222\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m29.222\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emission'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longitude'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m29.222\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcoeff_29222\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1793\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1795\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1879\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1880\u001b[0m                     \u001b[0;34m\"Must have equal len keys and value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m                     \u001b[0;34m\"when setting with an iterable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coeff_low_values = 0.962\n",
        "\n",
        "coeff_hi_values = 0.995\n",
        "\n",
        "ss.loc[(test['ClusterNo'].isin([0,4])), 'emission'] = coeff_hi_values * ss.loc[(test['ClusterNo'].isin([0,4])), 'emission']\n",
        "\n",
        "ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']<=13), 'emission'] = coeff_low_values * ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']<=13), 'emission']\n",
        "ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']>=17)&(test['week_no']<=39), 'emission'] = coeff_low_values * ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']>=17)&(test['week_no']<=39), 'emission']\n",
        "ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']>=44), 'emission'] = coeff_low_values * ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']>=44), 'emission']"
      ],
      "metadata": {
        "id": "SMOoBcVuY-9d"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test['id'] = test[['latitude', 'longitude']].apply(lambda row: get_id(row), axis=1)\n",
        "test['id'] = test['id'].map(new_ids)\n",
        "\n",
        "ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']==13), 'emission'] = np.nan\n",
        "ss = ss.fillna(method='bfill')\n",
        "\n",
        "ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']==17), 'emission'] = np.nan\n",
        "ss = ss.fillna(method='ffill')\n",
        "\n",
        "ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']==39), 'emission'] = np.nan\n",
        "ss = ss.fillna(method='ffill')\n",
        "\n",
        "ss.loc[(test['ClusterNo'].isin([0,4]))&(test['week_no']==44), 'emission'] = np.nan\n",
        "ss = ss.fillna(method='bfill')"
      ],
      "metadata": {
        "id": "JoeP2-3QaWsj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss.drop(['id', 'week_no'], axis=1, inplace=True)\n",
        "ss.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "Slq8L3xxaYhX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jPMsnUvgaZx3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}