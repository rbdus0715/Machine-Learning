{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYaGQADUpvEDH+OeuYQAQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbdus0715/Machine-Learning/blob/main/study/cuda/01.intro-cuda/12.device_properties.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **저마다 다른 성능의 디바이스에서의 속성값을 확인하는 방법**\n",
        "\n",
        "|Property|Explanation|\n",
        "|--------|-----------|\n",
        "|name    |ASCII string|\n",
        "|Major/ minor|3.2, 5.2, 5.3과 같은 숫자를 통해서 디바이스의 계산 능력을 파악할 수 있도록 한다. 여기서, 3.2라면 Major가 3이고, minor가 2이다.|\n",
        "|totalGlobalMem|디바이스의 글로벌 메모리의 총 쓸 수 있는 공간을 바이트로 표현|\n",
        "|maxThreadsPerBlock|스레드 블럭당 최대 스레드 개수|\n",
        "|maxThreadsDim[3]|블럭의 각 차원의 최대 크기|\n",
        "|maxGridSize[3]|그리드의 각 차원의 최대 크기|\n",
        "|clockRate|클럭 주파수|\n",
        "|sharedMemPerBlock|스레드 블럭에서 공유 가능한 최대 공간을 바이트로 표현|\n",
        "|Warp size|warp는 스트리밍 멀티프로세서의 기본 실행 단위이며, 현재 모든 장치의 warp size는 32이다.\\|"
      ],
      "metadata": {
        "id": "me3J7x33kx3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YI3jpAvfkqEl"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <stdio.h>\n",
        "\n",
        "void query_device()\n",
        "{\n",
        "    // 사용 가능한 디바이스들이 몇 개 있는지\n",
        "    int deviceCount = 0;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "\n",
        "    if(deviceCount == 0)\n",
        "    {\n",
        "        printf(\"No CUDA support device found\");\n",
        "    }\n",
        "\n",
        "    int devNo = 0;\n",
        "    cudaDeviceProp iProp;\n",
        "    cudaGetDeviceProperties(&iProp, devNo);\n",
        "\n",
        "\tprintf(\"Device %d: %s\\n\", devNo, iProp.name);\n",
        "\tprintf(\"  Number of multiprocessors:                     %d\\n\",\n",
        "\t\tiProp.multiProcessorCount);\n",
        "\tprintf(\"  clock rate :                     %d\\n\",\n",
        "\t\tiProp.clockRate);\n",
        "\tprintf(\"  Compute capability       :                     %d.%d\\n\",\n",
        "\t\tiProp.major, iProp.minor);\n",
        "\tprintf(\"  Total amount of global memory:                 %4.2f KB\\n\",\n",
        "\t\tiProp.totalGlobalMem / 1024.0);\n",
        "\tprintf(\"  Total amount of constant memory:               %4.2f KB\\n\",\n",
        "\t\tiProp.totalConstMem / 1024.0);\n",
        "\tprintf(\"  Total amount of shared memory per block:       %4.2f KB\\n\",\n",
        "\t\tiProp.sharedMemPerBlock / 1024.0);\n",
        "\tprintf(\"  Total amount of shared memory per MP:          %4.2f KB\\n\",\n",
        "\t\tiProp.sharedMemPerMultiprocessor / 1024.0);\n",
        "\tprintf(\"  Total number of registers available per block: %d\\n\",\n",
        "\t\tiProp.regsPerBlock);\n",
        "\tprintf(\"  Warp size:                                     %d\\n\",\n",
        "\t\tiProp.warpSize);\n",
        "\tprintf(\"  Maximum number of threads per block:           %d\\n\",\n",
        "\t\tiProp.maxThreadsPerBlock);\n",
        "\tprintf(\"  Maximum number of threads per multiprocessor:  %d\\n\",\n",
        "\t\tiProp.maxThreadsPerMultiProcessor);\n",
        "\tprintf(\"  Maximum number of warps per multiprocessor:    %d\\n\",\n",
        "\t\tiProp.maxThreadsPerMultiProcessor / 32);\n",
        "\tprintf(\"  Maximum Grid size                         :    (%d,%d,%d)\\n\",\n",
        "\t\tiProp.maxGridSize[0], iProp.maxGridSize[1], iProp.maxGridSize[2]);\n",
        "\tprintf(\"  Maximum block dimension                   :    (%d,%d,%d)\\n\",\n",
        "\t\tiProp.maxThreadsDim[0], iProp.maxThreadsDim[1], iProp.maxThreadsDim[2]);\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    query_device();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rQmLtZuoj8_",
        "outputId": "3d23c045-a87f-4f79-f3dd-317d74978573"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0: Tesla T4\n",
            "  Number of multiprocessors:                     40\n",
            "  clock rate :                     1590000\n",
            "  Compute capability       :                     7.5\n",
            "  Total amount of global memory:                 15464256.00 KB\n",
            "  Total amount of constant memory:               64.00 KB\n",
            "  Total amount of shared memory per block:       48.00 KB\n",
            "  Total amount of shared memory per MP:          64.00 KB\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per block:           1024\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of warps per multiprocessor:    32\n",
            "  Maximum Grid size                         :    (2147483647,65535,65535)\n",
            "  Maximum block dimension                   :    (1024,1024,64)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}