{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOPLB6WwwWEDtkks6Zr0FVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbdus0715/Machine-Learning/blob/main/study/cuda/01.intro-cuda/03.hello_cuda_world.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(1) cuda setting**"
      ],
      "metadata": {
        "id": "PmrglWN8MUkA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu8i0yMkLYhh",
        "outputId": "0c2ed737-9a40-4e90-dc75-851299fcf492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w623hfuLaw4",
        "outputId": "fe263c70-8599-49bf-8a38-e9143a72159e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-29pmzahl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-29pmzahl\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4295 sha256=f651a20aaab998c9bb68eee46e9112549065a5adbfa599e1879e787526bb3170\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gq_oikn4/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3350jsqLilC",
        "outputId": "c612b3a7-909c-4c15-c632-bcd7048a780b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(2) CUDA program**\n",
        "CUDA program의 단계\n",
        "1. cpu의 초기 데이터를 gpu로 가져온다\n",
        "2. 커널을 실행하여 전송된 데이터에 대한 작업 수행\n",
        "3. 그 후 병렬 실행 결과를 cpu 컨텍스트로 다시 전송\n",
        "4. cpu와 gpu 실행을 위해 할당된 메모리를 시스템에 회수\n",
        "\n",
        "CUDA program의 요소\n",
        "- Host code : cpu에서 실행\n",
        "- Device code : gpu에서 실행"
      ],
      "metadata": {
        "id": "VoutmGLqMYt8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(3) hello cuda world 실습**\n",
        "```cpp\n",
        "__host__ // host에서 호출 가능한 code\n",
        "__device__ // device에서 호출 가능한 code\n",
        "__global__ // host에서 gpu를 이용하기 위해 호출하는 code (code -> kernel)\n",
        "```"
      ],
      "metadata": {
        "id": "Gf9mLRdhPBY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRYSUKA_Lkbh",
        "outputId": "9d42ef98-a4de-4a3f-b384-07a0fd7b438c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- hello cuda world**"
      ],
      "metadata": {
        "id": "APFIPUbPOspn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello_cuda() {\n",
        "    printf(\"hello CUDA world \\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    hello_cuda <<<1, 20 >>>();\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzCrVeDzPvzk",
        "outputId": "857c1d2e-0070-4d09-f8bb-02da7fee6ac1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**- vector 연산 구현**\n",
        "- device 메모리를 위한 api (할당, 회수)\n",
        "```cpp\n",
        "cudaError_t cudaMalloc(void ** ptr, size_t size) // 동적 할당\n",
        "cudaError_t cudaFree(void* ptr) // 동적 할당 해제\n",
        "```\n",
        "- host, device 간의 데이터 복사\n",
        "```cpp\n",
        "// dst: destination 메모리 주소\n",
        "// src: source 메모리 주소\n",
        "// count: 복사할 byte 수\n",
        "// kind: 데이터 전송 타입, ex)host to device, device to host\n",
        "cudaMemcpy(void* dst, const void* src, size_t size, enum cudaMemcpyKind kind)\n",
        "// kind에 들어갈 값\n",
        "// cudaMemcpyHostToHost : cpu에서 cpu로 복사\n",
        "// cudaMemcpyHostToDevice : cpu에서 gpu로 복사\n",
        "// cudaMemcpyDeviceToHost : gpu에서 cpu로 복사\n",
        "// cudaMemcpyDeviceToDevice : gpu에서 gpu로 복사\n",
        "// cudaMemcpyDefault\n",
        "```"
      ],
      "metadata": {
        "id": "qW_1Dg4WOv72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "\n",
        "#define NUM_DATA 512\n",
        "\n",
        "__global__ void vecAdd(int *_a, int *_b, int *_c) {\n",
        "    int tID = threadIdx.x;\n",
        "    _c[tID] = _a[tID] + _b[tID];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "    // 1.\n",
        "    // host 메모리와 device 메모리가 독립적이기 때문에 따로따로 변수를 선언해주고 복사\n",
        "    int *a, *b, *c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    int memSize = sizeof(int)*NUM_DATA;\n",
        "    printf(\"%d elements, memSize = %d bytes\\n\", NUM_DATA, memSize);\n",
        "\n",
        "\n",
        "    // 2.\n",
        "    // host 메모리에 데이터 세팅\n",
        "    a = new int[NUM_DATA]; memset(a, 0, memSize);\n",
        "    b = new int[NUM_DATA]; memset(b, 0, memSize);\n",
        "    c = new int[NUM_DATA]; memset(c, 0, memSize);\n",
        "\n",
        "    for(int i=0; i<NUM_DATA; i++) {\n",
        "        a[i] = rand() % 10;\n",
        "        b[i] = rand() % 10;\n",
        "    }\n",
        "\n",
        "\n",
        "    // 3.\n",
        "    // device 메모리를 할당하고, cudaMemcpy를 통해 host 데이터를 device로 넘겨준다.\n",
        "    cudaMalloc(&d_a, memSize);\n",
        "    cudaMalloc(&d_b, memSize);\n",
        "    cudaMalloc(&d_c, memSize);\n",
        "\n",
        "    cudaMemcpy(d_a, a, memSize, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, memSize, cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    // 4.\n",
        "    // 커널 호출\n",
        "    vecAdd <<<1, NUM_DATA>>>(d_a, d_b, d_c);\n",
        "\n",
        "    cudaMemcpy(c, d_c, memSize, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "    // 5.\n",
        "    // 결과 확인\n",
        "    bool result = true;\n",
        "    for(int i=0; i<NUM_DATA; i++) {\n",
        "        if((a[i] + b[i]) != c[i]) {\n",
        "            printf(\"[%d] the results is not matched! (%d, %d)\\n\", i, a[i]+b[i], c[i]);\n",
        "            result = false;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if(result) printf(\"gpu works well!\\n\");\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    delete[] a;\n",
        "    delete[] b;\n",
        "    delete[] c;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkQa8O8wOyLd",
        "outputId": "7882a298-2ed1-499a-83d0-67e0eec0db53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512 elements, memSize = 2048 bytes\n",
            "gpu works well!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **(4) CUDA 단위**\n",
        "- 스레드가 모여 블럭이 되고, 블럭이 모여 그리드가 된다.\n",
        "- thread -> warp -> block -> grid\n",
        "- 커널 함수에서의 kernel<<<a, b>>>\n",
        "    - Kernel_name<<<**number_of_blocks**, **thread_per_block**>>>(arguments)\n",
        "    - 쉽게 말해 a개의 블록이 각각 b개의 스레드를 가지고 있다는 뜻\n",
        "\n",
        "- 다차원 그리드와 블럭 표현하기 위한 dim3 변수\n",
        "    - dim3 variable_name(X, Y, Z)\n",
        "    - .x .y .z 를 통해 접근 가능\n",
        "\n",
        "- *예시 문제*\n",
        "    - 32개의 스레드가 배열된 1차원 그리드로 커널 실행\n",
        "    - 각 블록에 x차원으로 4개의 스레드가 있는 8개 스레드 블록\n",
        "```cpp\n",
        "dim3 block(4, 1, 1), dim3 grid(8, 1, 1);\n",
        "Kernel_name<<<grid, block>>>();\n",
        "```\n",
        "    \n",
        "- block size의 한계 범위 : $x \\leq 1024, y \\leq 1024, z \\leq 64$\n",
        "- block당 스레드 개수 : $x \\times  y \\times z \\leq 1024$ (그래픽  카드 종류에 따라 512개일수도)\n",
        "- grid :\n",
        "    - X 차원에 대해 최대 $1^{32}-1$ 개의 스레드 블럭\n",
        "    - Y, Z 차원에 대해 최대 65536 개의 스레드 블럭\n"
      ],
      "metadata": {
        "id": "xoecr5xBSh_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello_cuda() {\n",
        "    printf(\"hello CUDA world \\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    dim3 block(4);\n",
        "    dim3 grid(8);\n",
        "\n",
        "    hello_cuda <<<grid, block>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Veoz0ZkoQZh4",
        "outputId": "37401ff6-f4c7-4fba-ddea-fb2bd0792ea2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello_cuda() {\n",
        "    printf(\"hello CUDA world \\n\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int nx, ny;\n",
        "    nx = 16;\n",
        "    ny = 4;\n",
        "\n",
        "    // hello world를 64번 호출하게 됨\n",
        "    dim3 block(8, 2, 1);\n",
        "    dim3 grid(nx / block.x, ny / block.y, 1);\n",
        "\n",
        "    hello_cuda <<<grid, block>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaDeviceReset();\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "WmHhnnmoXWnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51c114a-7fbd-4d2a-8a0a-53ed1697cb35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "hello CUDA world \n",
            "\n"
          ]
        }
      ]
    }
  ]
}