{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAHgGzxnUJRX5H8oZlCiI/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbdus0715/Machine-Learning/blob/main/study/sklearn/evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정확도 (accuracy)\n",
        "- 오차 행렬 (confusion matrix)\n",
        "- 정밀도 (precision)\n",
        "- 재현율 (recall)\n",
        "- F1 스코어\n",
        "- ROC AUC"
      ],
      "metadata": {
        "id": "Ik6Emekpobe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **정확도**\n",
        "\n",
        "- 정확도 = 예측 결과가 일치한 데이터 건수 / 전체 예측 데이터 건수\n",
        "    - 장점 : 직관적\n",
        "    - 단점 : 데이터의 구성에 따라 모델의 성능을 왜곡할 수 있음\n",
        "\n",
        "- 어떻게 모델의 성능을 왜곡하는가?\n",
        "    - 탑승객이 남자인 경우보다 여자인 경우가 더 생존 확률이 높았기 때문에 별다른 알고리즘 없이 여자인 경우 생존, 남자인 경우 사망으로 예측하는 단순한 모델을 만들어도 정확도가 괜찮게 나올 수 있음\n"
      ],
      "metadata": {
        "id": "xkKta8Uhr6uf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXFXjUfwoUqz"
      },
      "outputs": [],
      "source": [
        "# 아래 DumClassifier로 훈련/예측해도 70%대의 정확도를 보인다.\n",
        "# 평가 방식이 잘못되었음을 알 수 있다.\n",
        "\n",
        "from sklearn.base import BaseEstimator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class DumClassifier(BaseEstimator):\n",
        "    def fit(self, X, y=None):\n",
        "        pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        pred = np.zeros((X.shape[0], 1))\n",
        "        for i in range(X.shape[0]):\n",
        "            if X['Sex'].iloc[i] == 1:\n",
        "                pred[i] = 0\n",
        "            else:\n",
        "                pred[i] = 1\n",
        "\n",
        "        return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **오차 행렬**\n",
        "\n",
        "- 이진 분류의 예측 오류가 얼만인지, 어떠한 유형의 오류가 발생하고 있는지를 함께 나타내는 지표\n",
        "\n",
        "![img](https://velog.velcdn.com/images%2Fsset2323%2Fpost%2F2fb704cf-8556-40fc-87a2-75b8feb32986%2Fimage.png)"
      ],
      "metadata": {
        "id": "gT7lQbduvBqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# confusion_matrix(정답, 예측결과) >> 오차 행렬 출력"
      ],
      "metadata": {
        "id": "VbkfJY9atZuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **정밀도 & 재현율**\n",
        "\n",
        "- 정밀도(precision) : TP / (FP + TP) : positive라고 예측한 것 중 정말 positive인 비율\n",
        "    - 예시) 스팸 메일이라고 분류한 것은 정말 스팸 메일이어야 함. 다른 중요한 메일이 사라지면 안되기 때문임\n",
        "    - **실제 Negative인 데이터를 Positive로 예측하면 악영향이 끼치는 경우**\n",
        "- 재현율(recall) : TP / (FN + TP) : 실제값이 positive인 데이터를 positive라고 말하는 비율\n",
        "    - 예시) 암 판정 모델 : 실제 암을 암이 아니라고 판단하면 큰일\n",
        "    - **실제 Positive인 데이터를 Negative로 예측하면 악영향을 끼치는 경우**"
      ],
      "metadata": {
        "id": "rfy-p-L6e6sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "def get_lr_eval(y_test, pred):\n",
        "    confusion = confusion_matrix(y_test, pred)\n",
        "    accuracy = accuracy_score(y_test, pred)\n",
        "    precision = precision_score(y_test, pred)\n",
        "    recall = recall_score(y_test, pred)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    print(accuracy, precision, recall)"
      ],
      "metadata": {
        "id": "EQ7qO2BpdUWH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def fillna(df):\n",
        "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "    df['Cabin'].fillna('N', inplace=True)\n",
        "    df['Embarked'].fillna('N', inplace=True)\n",
        "    df['Fare'].fillna(0, inplace=True)\n",
        "    return df\n",
        "\n",
        "def drop_features(df):\n",
        "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "def format_features(df):\n",
        "    df['Cabin'] = df['Cabin'].str[:1]\n",
        "    features = ['Cabin', 'Sex', 'Embarked']\n",
        "    for feature in features:\n",
        "        le = LabelEncoder()\n",
        "        le = le.fit(df[feature])\n",
        "        df[feature] = le.transform(df[feature])\n",
        "    return df\n",
        "\n",
        "def transform_features(df):\n",
        "    df = fillna(df)\n",
        "    df = drop_features(df)\n",
        "    df = format_features(df)\n",
        "    return df"
      ],
      "metadata": {
        "id": "bmLiGfNIyoIU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "t_df = pd.read_csv('train.csv')\n",
        "y_t_df = t_df['Survived']\n",
        "X_t_df = t_df.drop(['Survived'], axis=1)\n",
        "X_t_df = transform_features(X_t_df)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_t_df, y_t_df, test_size=0.2, random_state=11)\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(X_train, y_train)\n",
        "pred = lr.predict(X_test)\n",
        "\n",
        "get_lr_eval(y_test, pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCMUjQGfwO_y",
        "outputId": "dbb18b6d-e7e7-4d91-ee6f-b6856ea1e2c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[104  14]\n",
            " [ 13  48]]\n",
            "0.8491620111731844 0.7741935483870968 0.7868852459016393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 정밀도 / 재현율 트레이드오프\n",
        "    - 이진 분류에서는 임계값을 0.5로 정해서 이 기준값보다 크면 1, 작으면 0으로 분류한다.\n",
        "    - predict_proba : 학습이 완료된 분류 객체에서 호출 가능 > 예측 결과인 0, 1이 아니라 예측 확률 결과를 보여준다.\n"
      ],
      "metadata": {
        "id": "HX1f8k7s0juq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "pred_proba = lr.predict_proba(X_test)\n",
        "pred = lr.predict(X_test)\n",
        "\n",
        "print(pred_proba[:3])\n",
        "\n",
        "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
        "print('\\n어느쪽 확률이 더 큰지 비교해서 0, 1예측한다.\\n')\n",
        "print(pred_proba_result[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3aIE6nMzvel",
        "outputId": "0aaf2de8-d73a-4d60-cf1d-f73a481e48b5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.46197474 0.53802526]\n",
            " [0.87872398 0.12127602]\n",
            " [0.87719492 0.12280508]]\n",
            "\n",
            "어느쪽 확률이 더 큰지 비교해서 0, 1예측한다.\n",
            "\n",
            "[[0.46197474 0.53802526 1.        ]\n",
            " [0.87872398 0.12127602 0.        ]\n",
            " [0.87719492 0.12280508 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Binarizer\n",
        "# threshold 문턱을 정해두어 예측 확률에 대한 결과를 얻을 수 있음\n",
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "Data = [\n",
        "    [1, -1, 2],\n",
        "    [2, 0, 0],\n",
        "    [0, 1.1, 1.2]\n",
        "]\n",
        "\n",
        "##\n",
        "# threshold를 0.5로 해주면 일반적인 로지스틱 회귀와 같음\n",
        "binarizer = Binarizer(threshold=1.1)\n",
        "binarizer.fit_transform(Data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsseHrgg1hL3",
        "outputId": "01ac361b-1b76-4108-e345-94eba6cabbfe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**결과적으로**\n",
        " - 임계값(threshold)이 높아지면 Positive로 예측할 확률이 낮아지고 임계값이 낮아지면 Positive로 예측할 확률이 높아짐\n",
        " - 임계값이 낮아지면 TP가 늘고 FN이 줄어든다.\n",
        "\n",
        "**요약하면**\n",
        " - 임계값이 높아지면 precision이 증가한다.\n",
        " - 임계값이 낮아지면 recall이 증가한다.\n",
        "\n",
        "</br>\n",
        "*임계값을 넘으면 positive, 넘지 못하면 negative"
      ],
      "metadata": {
        "id": "yDyq1R4E4Lek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **F1 스코어**\n",
        "\n",
        "![img](https://images.velog.io/images/jadon/post/f06f1d40-605d-4f13-b6ce-35c220c82968/image.png)\n",
        "\n",
        "- 정밀도와 재현율을 결합한 지표로 어느 쪽에도 치우치지 않는 경우 F1 스코어가 높게 나온다."
      ],
      "metadata": {
        "id": "MfqsE7gA6PK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1 = f1_score(y_test, pred)\n",
        "f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJO3jSv35kp_",
        "outputId": "28039512-ff3d-4000-a878-5412bfd8886e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7804878048780488"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ROC 곡선과 AUC**\n",
        "- skip"
      ],
      "metadata": {
        "id": "HVFQ5V5x7iOB"
      }
    }
  ]
}